{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Language-Mixed Sentiment Data\n",
    "\n",
    "This notebook analyzes code-mixed Nepali-English data for:\n",
    "- **Language ratios** (Nepali/English/mixed)\n",
    "- **Vocabulary distribution**\n",
    "- **Sentiment label balance**\n",
    "- **Code-mixing density** (token-level)\n",
    "- **UMAP visualization** of word embeddings\n",
    "\n",
    "> _Visualizations are saved to `notebooks/eda_outputs/` and linked in the main README automatically._"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from collections import Counter\n",
    "\n",
    "# Output directory for figures\n",
    "output_dir = Path('../notebooks/eda_outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load processed data\n",
    "DATA_PATH = '../data/processed/sentiment_train.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lang_counts = df['language'].value_counts()\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.barplot(x=lang_counts.index, y=lang_counts.values, palette='viridis')\n",
    "plt.title('Language Distribution (Nepali/English/Mixed)')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir/'language_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Label Balance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "label_map = {0:'Negative', 1:'Neutral', 2:'Positive'}\n",
    "df['sentiment_label'] = df['label'].map(label_map)\n",
    "sentiment_counts = df['sentiment_label'].value_counts()\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='Set2')\n",
    "plt.title('Sentiment Label Balance')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir/'sentiment_balance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "all_words = ' '.join(df['processed_text'].astype(str)).split()\n",
    "word_counts = Counter(all_words)\n",
    "most_common = word_counts.most_common(25)\n",
    "words, counts = zip(*most_common)\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x=list(words), y=list(counts), palette='magma')\n",
    "plt.title('Top 25 Most Common Words')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir/'top_words.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-Mixing Density (Token-Level)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def is_nepali_token(token):\n",
    "    for char in token:\n",
    "        if '\u0900' <= char <= '\u097F':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df['num_nepali_tokens'] = df['processed_text'].apply(lambda x: sum(is_nepali_token(tok) for tok in str(x).split()))\n",
    "df['num_english_tokens'] = df['processed_text'].apply(lambda x: sum(tok.isascii() and tok.isalpha() for tok in str(x).split()))\n",
    "df['mix_density'] = df['num_nepali_tokens'] / (df['num_nepali_tokens'] + df['num_english_tokens'] + 1e-5)\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(df['mix_density'], bins=20, kde=True, color='teal')\n",
    "plt.title('Code-Mixing Density (Nepali tokens ratio)')\n",
    "plt.xlabel('Nepali token ratio')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir/'mix_density.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP Visualization of Word Embeddings (Language Overlap)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import umap\n",
    "\n",
    "# Use a subset for speed\n",
    "sample_texts = df['processed_text'].dropna().sample(n=200, random_state=42) if len(df) > 200 else df['processed_text'].dropna()\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = AutoModel.from_pretrained('xlm-roberta-base')\n",
    "model.eval()\n",
    "\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for text in sample_texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=32)\n",
    "        outputs = model(**inputs)\n",
    "        emb = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        embeddings.append(emb)\n",
    "\n",
    "embeddings = np.stack(embeddings)\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "umap_emb = reducer.fit_transform(embeddings)\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=umap_emb[:,0], y=umap_emb[:,1], hue=sample_texts.index.map(lambda i: df.loc[i, 'language']), palette='Set1', alpha=0.7)\n",
    "plt.title('UMAP Projection of Text Embeddings (Language Overlap)')\n",
    "plt.legend(title='Language')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir/'umap_embeddings.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Windsurf/README Integration\n",
    "\n",
    "- The figures above are saved to `notebooks/eda_outputs/`.\n",
    "- To update the main README with these outputs, run the script below or use a Windsurf automation.\n",
    "\n",
    "```python\n",
    "# Update README.md with EDA outputs\n",
    "from pathlib import Path\n",
    "eda_dir = Path('notebooks/eda_outputs')\n",
    "readme_path = Path('README.md')\n",
    "figs = list(eda_dir.glob('*.png'))\n",
    "with readme_path.open('a') as f:\n",
    "    f.write('\n## Exploratory Data Analysis (Auto-Generated)\n')\n",
    "    for fig in figs:\n",
    "        f.write(f'![EDA Output]({fig})\n')\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
